 
###############################################################################
# Fonctions génériques utilisées par les scripts BD6
###############################################################################

###############################################################################
# fg_gen_properties : 
#   génération du fichier properties pour les traitements java, depuis un
#   fichier .ini contenant des variables d'environnement
###############################################################################
# Arguments
# - Chemin complet du fichier .ini
# - Chemin complet du fichier properties à générer
###############################################################################
function fg_gen_properties {
set -x
    typeset _file_ini="$1"
    typeset _file_dest="$2"
    typeset _line
    
    jobEtape "$0 : generation du fichier $_file_dest"
    > "$_file_dest"
    while read _line; do
        # Si la ligne contient un $, on essaie d'évaluer la variable, sauf si # en début de ligne
        if [[ $_line == *\$* ]] && $(echo "$_line" | egrep -vq '^\s*#'); then
            eval echo "$_line" >> "$_file_dest"
        else
            echo "$_line" >> "$_file_dest"
        fi
    done < "$_file_ini"
    jobTest $? "$0 : erreur lors de la generation du fichier $_file_dest"
    
}

###############################################################################
# fg_kinit : 
#   récupération d'un ticket Kerberos via appel de l'utilitaire kinit
###############################################################################
# Arguments
# - Chemin complet du fichier keytab à utiliser
# - Nom du user à utiliser
###############################################################################
function fg_kinit {
set -x
    typeset _keytab="$1"
    typeset _user="$2"
    
    jobEtape "$0 : authentification Kerberos"
    
    if [[ ! -r $_keytab ]]; then
        echo "$0 : Le fichier $_keytab n'existe pas ou n'est pas accessible"
        exit 1
    fi
    
    kinit -kt "$_keytab" "$_user"
    jobTest $? "$0 : Erreur lors de l'authentification Kerberos"
    
}

###############################################################################
# fl_exec_hql : 
#   Execute a HiveQL statement (with optional beeline options)
###############################################################################
# Arguments
# - Chemin complet du script HQL à exécuter
###############################################################################

# -----------------------------------------------------------------------------
# Execute a HiveQL statement (with optional beeline options)
# -----------------------------------------------------------------------------
function fl_exec_hql {
set -x
        echo "---- Chargement HDFS - $date ----"

        command -v beeline >/dev/null 2>&1 || {
                echo "$FUNCNAME: beeline not available"
                return 1
        }

        #[ $# -eq 0 ] && echo "$FUNCNAME: at least one argument is required" && return 2
        #[ $# -ne 1 ] && echo "Erreur : script HQL manquant en parametre." && return 2

        typeset _fileHql=$1
        typeset _dToday=$(date +%Y%m%d)

        [ ! -s ${_YCDSQL}/${_fileHql} ] && echo -e "Erreur : Le fichier ${_fileHql} est absent du dossier ${_YCDSQL}." && return 2

        echo -e "$0 : Lancement du script $_fileHql - $(date +%Y%m%d.%H%M%S)"

        beeline \
        -u ${HIVE_JDBC_ZOOKEEPER} \
        -f ${_YCDSQL}/${_fileHql} \
        -n ${username} \
        --hivevar env=${ENV_DSN} \
        --hivevar hive_jdbc_cnx=${HIVE_JDBC_ZOOKEEPER} \
        --hivevar code_app=${_YCICODE} \
        --hivevar date_ctrlm=${DATE_CTRLM} 

        if (( $? != 0 )); then
                echo -e "$0 : Erreur dans le lancement de la commande beeline"
                # jobTest $? "$0 : Erreur lors de la creation des tables Hive."
                exit 1
        else
                echo -e "$0 : Execution du script $_fileHql TERMINE - "
                return 0
        fi
}

###############################################################################
# fl_exec_hql_with_hivevar : 
#   Execute a HiveQL statement with optional hivevar
###############################################################################
# Arguments
# - Nom du script HQL à exécuter
# - Nom des variables de type hivevar à créer suivi de la valeur à donner
###############################################################################

# -----------------------------------------------------------------------------
# Execute a HiveQL statement 
# -----------------------------------------------------------------------------
function fl_exec_hql_with_hivevar {
set -x
        echo "---- Chargement HDFS - $date ----"

        command -v beeline >/dev/null 2>&1 || {
                echo "$FUNCNAME: beeline not available"
                return 1
        }

        #[ $# -eq 0 ] && echo "$FUNCNAME: at least one argument is required" && return 2
        #[ $# -ne 1 ] && echo "Erreur : script HQL manquant en parametre." && return 2

        typeset _fileHql=$1
        typeset _dToday=$(date +%Y%m%d)

        [ ! -s ${_YCDSQL}/${_fileHql} ] && echo -e "Erreur : Le fichier ${_fileHql} est absent du dossier ${_YCDSQL}." && return 2

        # on test si le nombre d'arguments est pair ou non car on veut un nombre impair d'arguments
        # en effet on a en premier argument le nom du fichier HQL et ensuite un nom d'une varibale suivi d'une valeur
        # ET on ne veut pas un nom de variable sans valeur
        if [ "`expr $# % 2`" = "0" ]
        then 
            echo "error : il faut un nombre pair d'arguments (un nom de variable est toujours suivi d'une valeur)"
            exit 1
        else 
            # commencer à partir du 2eme argument car le premier est le nom du fichier hql
            for arg in ${@:2}
            do
                # compteur pour identifier si on traite un nom de variable ou une valeur 
                compteur=$((compteur+1))
                echo "traitement de l'arg: $arg"
                if [ "`expr $compteur % 2`" = "0" ]
                then
                    concat_hive_var=${concat_hive_var}"$arg"
                else 
                    concat_hive_var=${concat_hive_var}" --hivevar $arg="
                fi
            done
        fi

        echo "arguments hivevar ajoutés au beeline : $concat_hive_var"

        echo -e "$0 : Lancement du script $_fileHql - $(date +%Y%m%d.%H%M%S)"

        beeline \
        -u ${HIVE_JDBC_CNX} \
        -f ${_YCDSQL}/${_fileHql} \
        -n ${username} \
        --hivevar env=${ENV_DSN} \
        --hivevar hive_jdbc_cnx=${HIVE_JDBC_CNX} \
        --hivevar code_app=${_YCICODE} \
        --hivevar date_ctrlm=${DATE_CTRLM} \
        ${concat_hive_var}

        if (( $? != 0 )); then
                echo -e "$0 : Erreur dans le lancement de la commande beeline"
                # jobTest $? "$0 : Erreur lors de la creation des tables Hive."
                exit 1
        else
                echo -e "$0 : Execution du script $_fileHql TERMINE - "
                return 0
        fi
}

# -----------------------------------------------------------------------------
# Execute a Indexima SQL statement (with optional beeline options)
# -----------------------------------------------------------------------------
function fl_exec_indexima_hql {
set -x
        echo "---- Chargement HDFS - $date ----"

        command -v beeline >/dev/null 2>&1 || {
                echo "$FUNCNAME: beeline not available"
                return 1
        }

        [ $# -eq 0 ] && echo "$FUNCNAME: at least one argument is required" && return 2
        [ $# -ne 1 ] && echo "Erreur : script HQL manquant en parametre." && return 2

        typeset _fileHql=$1
        typeset _dToday=$(date +%Y%m%d)
        

        [ ! -s ${_YCDSQL}/${_fileHql} ] && echo -e "Erreur : Le fichier ${_fileHql} est absent du dossier ${_YCDSQL}." && return 2

        echo -e "$0 : Lancement du script $_fileHql - $(date +%Y%m%d.%H%M%S)"

        beeline \
        -u ${INDEXIMA_JDBC_ZOOKEEPER} \
        -f ${_YCDSQL}/${_fileHql} \
        -n ${username} \
        --hivevar env=${ENV_DSN} \
        --hivevar hive_jdbc_for_indexima=${INDEXIMA_JDBC_ZOOKEEPER} \
        --hivevar code_app=${_YCICODE} 

        if (( $? != 0 )); then
                echo -e "$0 : Erreur dans le lancement de la commande beeline"
                # jobTest $? "$0 : Erreur lors de la creation des tables Hive."
                exit 1
        else
                echo -e "$0 : Execution du script $_fileHql TERMINE - "
                return 0
        fi
}


# -----------------------------------------------------------------------------
# Execute a Indexima SQL statement (with optional beeline options)
# -----------------------------------------------------------------------------
function get_yarn_spark_log {
set -x

    # Récupération de l'ID d'exécution SPARK pour récupérer la log
    SPARK_EXEC_ID=$(grep -oP '(?<=Submitted application )application_\d+_\d+' ${TRACE})
    if echo $SPARK_EXEC_ID | egrep 'application_[0-9]+_[0-9]+'
        then
            echo "Identifiant SPARK trouvé : ${SPARK_EXEC_ID}"

            # Copie de la log et archivage dans HDFS
            yarn logs -applicationId ${SPARK_EXEC_ID} -log_files stdout > ${LOCAL_YARN_TRACE}

            # Si le fichier existe on l'historise sous hdfs
            if [[ -e "$LOCAL_YARN_TRACE" ]]; then

                # lancer la commande deplacement des rapports dans le dossier d'archive 
                hdfs dfs -mkdir -p ${HDFS_YARN_TRACE}
            
                # lancer la commande HDFS DFS put depuis edge vers le rep staging hdfs 
                hdfs dfs -put -f ${LOCAL_YARN_TRACE} ${HDFS_YARN_TRACE} 
            fi
        else
            echo "Identifiant SPARK non trouvé"
    fi
}

######################################################
#Fonction spark submit################################
######################################################


function sparksubmit	{
set -x
		jobEtape "sparksubmit : Debut de sparksubmit ${_YCICODE}"
        #execution du spark-submit en deploy-mode $DEPLOY_MODE
        # Lancement du Spark submit 

		spark-submit \
		--name ${_YCICODE} \
		--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=$APP_MASTER_ENV \
		--conf spark.yarn.maxAppAttempts=1 \
		--conf spark.yarn.appMasterEnv.KRB5CCNAME="./tmp/${TMP_TGT_NAME}"\
		--conf spark.ui.view.acls=$SPARKUI_USERS \
		--conf spark.ui.view.acls.groups="gf_hdp_dev_${_YCICODE}_moe" \
		--conf spark.hadoop.dfs.nameservices=${internal_nameservice} \
		--conf spark.datasource.hive.warehouse.read.mode=DIRECT_READER_V2 \
		--conf 'spark.sql.sources.partitionOverwriteMode=dynamic' \
        --conf 'spark.sql.legacy.timeParserPolicy=LEGACY'\
		--conf 'spark.sql.sources.commitProtocolClass=org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol' \
		--conf spark.hadoop.dfs.namenode.kerberos.principal.pattern='*' \
		--master yarn  \
		--deploy-mode cluster  \
		--archives $ARCHIVES \
		--py-files ${_YCDBIN}/job_${_YCDAPPNAME}.zip,${KRB5CCNAME}\#./tmp/${TMP_TGT_NAME} \
		--files ${_YCDPARM}/*.json,/etc/hive/conf.cloudera.hive/hive-site.xml,${_YCDPARM}/${APP_CONF_FILE},${_YCDPARM}/${_YCICODE}_logging.conf  \
		--packages org.elasticsearch:elasticsearch-hadoop:7.2.0,com.databricks:spark-avro_2.11:4.0.0,com.databricks:spark-xml_2.11:0.4.1,org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0  \
		--driver-memory $DRIVER_MEMORY \
		--num-executors $NUM_EXECUTORS \
		--executor-memory $EXECUTOR_MEMORY \
		--executor-cores $EXECUTOR_CORES  \
		--queue $ENV_DSN ${MAIN}  \
		--logconfiguration=${_YCICODE}_logging.conf \
        --jobconfiguration=${APP_CONF_FILE} \
		--ctrlm=${DATE_CTRLM}
	}

function spark3submit	{
set -x
		jobEtape "spark3submit : Debut de spark3submit ${_YCICODE}"
        #execution du spark-submit en deploy-mode $DEPLOY_MODE
        # Lancement du Spark submit 
        echo $APP_MASTER_ENV
        echo ${internal_nameservice}
        echo $ENV_DSN 
        echo ${MAIN}

        if [ "${YCIENV}" = "X" ]
        then
            _maxAppAttempts=2
        else
            _maxAppAttempts=1
        fi
        
		spark3-submit \
		--name ${_YCICODE} \
		--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=$APP_MASTER_ENV \
		--conf spark.yarn.maxAppAttempts=${_maxAppAttempts} \
		--conf spark.yarn.appMasterEnv.KRB5CCNAME="./tmp/${TMP_TGT_NAME}"\
		--conf spark.ui.view.acls=$SPARKUI_USERS \
		--conf spark.ui.view.acls.groups="gf_hdp_dev_${_YCICODE}_moe" \
		--conf spark.hadoop.dfs.nameservices=${internal_nameservice} \
		--conf spark.datasource.hive.warehouse.read.mode=DIRECT_READER_V2 \
		--conf 'spark.sql.sources.partitionOverwriteMode=dynamic' \
        --conf 'spark.sql.legacy.timeParserPolicy=LEGACY'\
		--conf 'spark.sql.sources.commitProtocolClass=org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol' \
		--conf 'spark.sql.adaptive.enabled=True'\
        --conf 'spark.sql.adaptive.coalescePartitions.enabled=True'\
        --conf 'spark.sql.adaptive.advisoryPartitionSizeInBytes=128m'\
        --conf 'spark.sql.adaptive.coalescePartitions.minPartitionNum=1'\
        --conf spark.hadoop.dfs.namenode.kerberos.principal.pattern='*' \
		--master yarn  \
        --deploy-mode cluster  \
		--archives $ARCHIVES \
		--files  ${KRB5CCNAME}\#./tmp/${TMP_TGT_NAME},${_YCDPARM}/*.json,/etc/hive/conf.cloudera.hive/hive-site.xml,${_YCDPARM}/${APP_CONF_FILE},${_YCDPARM}/${_YCICODE}_logging.conf  \
        --jars "${IMPALA_JAR}" --driver-class-path "${IMPALA_JAR}" \
        --driver-memory $DRIVER_MEMORY \
		--num-executors $NUM_EXECUTORS \
		--executor-memory $EXECUTOR_MEMORY \
		--executor-cores $EXECUTOR_CORES  \
		--queue $ENV_DSN ${MAIN}  \
		--logconfiguration=${_YCICODE}_logging.conf \
        --jobconfiguration=${APP_CONF_FILE} \
        --ctrlm=${DATE_CTRLM}
	}

# fonction spark submit dans laquelle on peut rajouter des arguments depuis le KSH
# exemple : sparksubmit_CDP_add_args --conf 'spark.conf=oui' --py-files /path/to/file --package mypackage:0.22
function sparksubmit_CDP_add_args	{
set -x

    more_conf=""
	more_pyfiles=""
	more_files=""
	more_packages=""

    while [ ! -z "$1" ]
	do
		case "$1" in
			--conf)
				shift
                more_conf+=" --conf '$1'"
				;;
			--py-files)
				shift
                more_pyfiles+=",$1"
				;;
            --files)
				shift
                more_files+=",$1"
				;;
            --packages)
				shift
				more_packages+=",$1"
				;;
		esac
		shift
	done

        jobEtape "sparksubmit : Debut de sparksubmit ${_YCICODE}"
        #execution du spark-submit en deploy-mode $DEPLOY_MODE
        # Lancement du Spark submit 

        spark-submit \
        --name ${_YCICODE} \
        --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=$APP_MASTER_ENV \
        --conf spark.yarn.maxAppAttempts=1 \
        --conf spark.yarn.appMasterEnv.KRB5CCNAME="./tmp/${TMP_TGT_NAME}"\
        --conf spark.ui.view.acls=$SPARKUI_USERS \
        --conf spark.ui.view.acls.groups="gf_hdp_dev_${_YCICODE}_moe" \
        --conf spark.hadoop.dfs.nameservices=${internal_nameservice} \
        --conf spark.datasource.hive.warehouse.read.mode=DIRECT_READER_V2 \
        --conf 'spark.sql.sources.partitionOverwriteMode=dynamic' \
        --conf 'spark.sql.sources.commitProtocolClass=org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol' \
        --conf spark.hadoop.dfs.namenode.kerberos.principal.pattern='*' \
        $more_conf \
        --master yarn  \
        --deploy-mode cluster  \
        --archives $ARCHIVES \
        --py-files ${_YCDBIN}/job_${_YCDAPPNAME}.zip,${KRB5CCNAME}\#./tmp/${TMP_TGT_NAME}${more_pyfiles} \
        --files ${_YCDPARM}/*.json,/etc/hive/conf.cloudera.hive/hive-site.xml,${_YCDPARM}/${_YCICODE}.conf,${_YCDPARM}/${_YCICODE}_logging.conf${more_files}  \
        --packages org.elasticsearch:elasticsearch-hadoop:7.2.0,com.databricks:spark-avro_2.11:4.0.0,com.databricks:spark-xml_2.11:0.4.1,org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0${more_packages}  \
        --driver-memory $DRIVER_MEMORY \
        --num-executors $NUM_EXECUTORS \
        --executor-memory $EXECUTOR_MEMORY \
        --executor-cores $EXECUTOR_CORES  \
        --queue $ENV_DSN ${MAIN}  \
        --logconfiguration=${_YCICODE}_logging.conf \
        --jobconfiguration=${_YCICODE}.conf \
        --ctrlm=${DATE_CTRLM}
}
