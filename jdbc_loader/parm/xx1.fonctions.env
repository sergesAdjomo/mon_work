

###############################################################################

# Fonctions génériques utilisées par les scripts BD6

###############################################################################

###############################################################################

# fg_gen_properties :

# génération du fichier properties pour les traitements java, depuis un

# fichier .ini contenant des variables d'environnement

###############################################################################

# Arguments

# - Chemin complet du fichier .ini

# - Chemin complet du fichier properties à générer

###############################################################################

function fg_gen_properties {

set -x

typeset fileini="$1"

typeset filedest="$2"

typeset _line



jobEtape "$0 : generation du fichier $_file_dest"

> "$_file_dest"

while read _line; do

# Si la ligne contient un $, on essaie d'évaluer la variable, sauf si # en début de ligne

if [[ $_line == \$ ]] && $(echo "$_line" | egrep -vq '^\s*#'); then

eval echo "$_line" >> "$_file_dest"

else

echo "$_line" >> "$_file_dest"

fi

done < "$_file_ini"

jobTest $? "$0 : erreur lors de la generation du fichier $_file_dest"



}

###############################################################################

# fg_kinit :

# récupération d'un ticket Kerberos via appel de l'utilitaire kinit

###############################################################################

# Arguments

# - Chemin complet du fichier keytab à utiliser

# - Nom du user à utiliser

###############################################################################

function fg_kinit {

set -x

typeset _keytab="$1"

typeset _user="$2"



jobEtape "$0 : authentification Kerberos"



if [[ ! -r $_keytab ]]; then

echo "$0 : Le fichier $_keytab n'existe pas ou n'est pas accessible"

exit 1

fi



kinit -kt "$_keytab" "$_user"

jobTest $? "$0 : Erreur lors de l'authentification Kerberos"



}

###############################################################################

# fl_exec_hql :

# Execute a HiveQL statement (with optional beeline options)

###############################################################################

# Arguments

# - Chemin complet du script HQL à exécuter

###############################################################################

# -----------------------------------------------------------------------------

# Execute a HiveQL statement (with optional beeline options)

# -----------------------------------------------------------------------------

function fl_exec_hql {

set -x

echo "---- Chargement HDFS - $date ----"

command -v beeline >/dev/null 2>&1 || {

echo "$FUNCNAME: beeline not available"

return 1

}

#[ $# -eq 0 ] && echo "$FUNCNAME: at least one argument is required" && return 2

#[ $# -ne 1 ] && echo "Erreur : script HQL manquant en parametre." && return 2

typeset _fileHql=$1

typeset _dToday=$(date +%Y%m%d)

[ ! -s ${_YCDSQL}/${_fileHql} ] && echo -e "Erreur : Le fichier ${_fileHql} est absent du dossier ${_YCDSQL}." && return 2

echo -e "$0 : Lancement du script $_fileHql - $(date +%Y%m%d.%H%M%S)"

beeline \

-u ${HIVE_JDBC_ZOOKEEPER} \

-f ${_YCDSQL}/${_fileHql} \

-n ${username} \

--hivevar env=${ENV_DSN} \

--hivevar hive_jdbc_cnx=${HIVE_JDBC_ZOOKEEPER} \

--hivevar code_app=${_YCICODE} \

--hivevar date_ctrlm=${DATE_CTRLM}

if (( $? != 0 )); then

echo -e "$0 : Erreur dans le lancement de la commande beeline"

# jobTest $? "$0 : Erreur lors de la creation des tables Hive."

exit 1

else

echo -e "$0 : Execution du script $_fileHql TERMINE - "

return 0

fi

}

###############################################################################

# fl_exec_hql_with_hivevar :

# Execute a HiveQL statement with optional hivevar

###############################################################################

# Arguments

# - Nom du script HQL à exécuter

# - Nom des variables de type hivevar à créer suivi de la valeur à donner

###############################################################################

# -----------------------------------------------------------------------------

# Execute a HiveQL statement

# -----------------------------------------------------------------------------

function fl_exec_hql_with_hivevar {

set -x

echo "---- Chargement HDFS - $date ----"

command -v beeline >/dev/null 2>&1 || {

echo "$FUNCNAME: beeline not available"

return 1

}

#[ $# -eq 0 ] && echo "$FUNCNAME: at least one argument is required" && return 2

#[ $# -ne 1 ] && echo "Erreur : script HQL manquant en parametre." && return 2

typeset _fileHql=$1

typeset _dToday=$(date +%Y%m%d)

[ ! -s ${_YCDSQL}/${_fileHql} ] && echo -e "Erreur : Le fichier ${_fileHql} est absent du dossier ${_YCDSQL}." && return 2

# on test si le nombre d'arguments est pair ou non car on veut un nombre impair d'arguments

# en effet on a en premier argument le nom du fichier HQL et ensuite un nom d'une varibale suivi d'une valeur

# ET on ne veut pas un nom de variable sans valeur

if [ expr $# % 2" = "0" ]

then

echo "error : il faut un nombre pair d'arguments (un nom de variable est toujours suivi d'une valeur)"

exit 1

else

# commencer à partir du 2eme argument car le premier est le nom du fichier hql

for arg in ${@:2}

do

# compteur pour identifier si on traite un nom de variable ou une valeur

compteur=$((compteur+1))

echo "traitement de l'arg: $arg"

if [ expr $compteur % 2" = "0" ]

then

concat_hive_var=${concat_hive_var}"$arg"

else

concat_hive_var=${concat_hive_var}" --hivevar $arg="

fi

done

fi

echo "arguments hivevar ajoutés au beeline : $concat_hive_var"

echo -e "$0 : Lancement du script $_fileHql - $(date +%Y%m%d.%H%M%S)"

beeline \

-u ${HIVE_JDBC_CNX} \

-f ${_YCDSQL}/${_fileHql} \

-n ${username} \

--hivevar env=${ENV_DSN} \

--hivevar hive_jdbc_cnx=${HIVE_JDBC_CNX} \

--hivevar code_app=${_YCICODE} \

--hivevar date_ctrlm=${DATE_CTRLM} \

${concat_hive_var}

if (( $? != 0 )); then

echo -e "$0 : Erreur dans le lancement de la commande beeline"

# jobTest $? "$0 : Erreur lors de la creation des tables Hive."

exit 1

else

echo -e "$0 : Execution du script $_fileHql TERMINE - "

return 0

fi

}

# -----------------------------------------------------------------------------

# Execute a Indexima SQL statement (with optional beeline options)

# -----------------------------------------------------------------------------

function fl_exec_indexima_hql {

set -x

echo "---- Chargement HDFS - $date ----"

command -v beeline >/dev/null 2>&1 || {

echo "$FUNCNAME: beeline not available"

return 1

}

[ $# -eq 0 ] && echo "$FUNCNAME: at least one argument is required" && return 2

[ $# -ne 1 ] && echo "Erreur : script HQL manquant en parametre." && return 2

typeset _fileHql=$1

typeset _dToday=$(date +%Y%m%d)



[ ! -s ${_YCDSQL}/${_fileHql} ] && echo -e "Erreur : Le fichier ${_fileHql} est absent du dossier ${_YCDSQL}." && return 2

echo -e "$0 : Lancement du script $_fileHql - $(date +%Y%m%d.%H%M%S)"

beeline \

-u ${INDEXIMA_JDBC_ZOOKEEPER} \

-f ${_YCDSQL}/${_fileHql} \

-n ${username} \

--hivevar env=${ENV_DSN} \

--hivevar hive_jdbc_for_indexima=${INDEXIMA_JDBC_ZOOKEEPER} \

--hivevar code_app=${_YCICODE}

if (( $? != 0 )); then

echo -e "$0 : Erreur dans le lancement de la commande beeline"

# jobTest $? "$0 : Erreur lors de la creation des tables Hive."

exit 1

else

echo -e "$0 : Execution du script $_fileHql TERMINE - "

return 0

fi

}

# -----------------------------------------------------------------------------

# Execute a Indexima SQL statement (with optional beeline options)

# -----------------------------------------------------------------------------

function get_yarn_spark_log {

set -x

# Récupération de l'ID d'exécution SPARK pour récupérer la log

SPARK_EXEC_ID=$(grep -oP '(?<=Submitted application )application_\d+_\d+' ${TRACE})

if echo $SPARK_EXEC_ID | egrep 'application_[0-9]+_[0-9]+'

then

echo "Identifiant SPARK trouvé : ${SPARK_EXEC_ID}"

# Copie de la log et archivage dans HDFS

yarn logs -applicationId ${SPARK_EXEC_ID} -log_files stdout > ${LOCAL_YARN_TRACE}

# Si le fichier existe on l'historise sous hdfs

if [[ -e "$LOCAL_YARN_TRACE" ]]; then

# lancer la commande deplacement des rapports dans le dossier d'archive

hdfs dfs -mkdir -p ${HDFS_YARN_TRACE}



# lancer la commande HDFS DFS put depuis edge vers le rep staging hdfs

hdfs dfs -put -f ${LOCAL_YARN_TRACE} ${HDFS_YARN_TRACE}

fi

else

echo "Identifiant SPARK non trouvé"

fi

}

######################################################

#Fonction spark submit################################

######################################################

function spark3submit {

set -x

jobEtape "sparksubmit : Debut de sparksubmit ${_YCICODE}"



# Lancement du Spark submit

if [ "${YCIENV}" = "X" ]

then

_maxAppAttempts=2

else

_maxAppAttempts=1

fi



spark3-submit \

--name ${_YCICODE} \

--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=$APP_MASTER_ENV \

--conf spark.yarn.maxAppAttempts=${_maxAppAttempts} \

--conf spark.yarn.tags=${_YCICODE}_${_YCIJOBNAME} \

--conf spark.yarn.appMasterEnv.KRB5CCNAME="./tmp/${TMP_TGT_NAME}"\

--conf spark.ui.view.acls=$SPARKUI_USERS \

--conf spark.ui.view.acls.groups="gf_hdp_dev_${_YCICODE}_moe" \

--conf spark.hadoop.dfs.nameservices=${internal_nameservice} \

--conf spark.datasource.hive.warehouse.read.mode=DIRECT_READER_V2 \

--conf 'spark.sql.sources.partitionOverwriteMode=dynamic' \

--conf 'spark.sql.sources.commitProtocolClass=org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol' \

--conf spark.hadoop.dfs.namenode.kerberos.principal.pattern='*' \

--conf 'spark.sql.parquet.writeLegacyFormat=true' \

--conf 'spark.sql.legacy.timeParserPolicy=LEGACY' \

--conf 'spark.executor.extraJavaOptions=-Xss1G' \

--conf 'spark.driver.extraJavaOptions=-Xss1G' \

--conf spark.dynamicAllocation.initialExecutors=1 \

--conf spark.dynamicAllocation.minExecutors=1 \

--conf "spark.sql.session.timeZone=Europe/Paris" \

--master yarn \

--deploy-mode cluster \

--archives $ARCHIVES \

--files $JSON_FILE,/etc/hive/conf.cloudera.hive/hive-site.xml,${_YCDPARM}/${APP_CONF_FILE},${_YCDPARM}/${_YCICODE}_logging.conf \

--driver-memory $DRIVER_MEMORY \

--num-executors $NUM_EXECUTORS \

--executor-memory $EXECUTOR_MEMORY \

--executor-cores $EXECUTOR_CORES \

--jars /opt/cloudera/parcels/CDH/jars/postgresql-*.jar,/usr/share/java/ojdbc6.jar,"${IMPALA_JAR}",/usr/share/java/mysql-connector-j.jar --driver-class-path "${IMPALA_JAR}",/usr/share/java/mysql-connector-j.jar ${MAIN} --logconfiguration=${_YCICODE}_logging.conf --jobconfiguration=${APP_CONF_FILE} --ctrlm=${DATE_CTRLM}

}